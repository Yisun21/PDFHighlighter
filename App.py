import streamlit as st
import fitz  # PyMuPDF
import pandas as pd
import tempfile
import os
import gc  # åƒåœ¾å›æ”¶

# --- é¡µé¢é…ç½® ---
st.set_page_config(page_title="PDF å…¨è¯åŒ¹é…é«˜äº®å·¥å…·", page_icon="ğŸ¯", layout="wide")


# --- ç¼“å­˜å‡½æ•° ---
@st.cache_data(ttl=3600)
def load_excel_data(file):
    try:
        df = pd.read_excel(file)
        # è¯»å–ç¬¬ä¸€åˆ—ï¼Œå»é‡ï¼Œè½¬å­—ç¬¦ä¸²ï¼Œå»é™¤é¦–å°¾ç©ºæ ¼
        return df.iloc[:, 0].dropna().astype(str).str.strip().unique().tolist()
    except Exception:
        return []


def hex_to_rgb(hex_color):
    hex_color = hex_color.lstrip('#')
    return tuple(int(hex_color[i:i + 2], 16) / 255.0 for i in (0, 2, 4))


# --- åˆå§‹åŒ– Session State ---
if 'word_libraries' not in st.session_state:
    st.session_state['word_libraries'] = {}

# --- ä¾§è¾¹æ  UI ---
with st.sidebar:
    st.title("ğŸ¯ ç²¾å‡†è®¾ç½®")

    st.subheader("1. æ–‡ä»¶")
    uploaded_pdf = st.file_uploader("ä¸Šä¼  PDF", type=["pdf"], label_visibility="collapsed")

    st.divider()

    st.subheader("2. è¯åº“ (Excel)")
    uploaded_excels = st.file_uploader(
        "ä¸Šä¼ è¯åº“ï¼ˆå•è¯æ”¾Excelè¡¨æ ¼ç¬¬ä¸€åˆ—ï¼‰ (.xlsx)",
        type=['xlsx'],
        accept_multiple_files=True
    )

    if uploaded_excels:
        for excel_file in uploaded_excels:
            if excel_file.name not in st.session_state['word_libraries']:
                words = load_excel_data(excel_file)
                if words:
                    st.session_state['word_libraries'][excel_file.name] = {
                        'words': words,
                        'default_color': '#FFFF00'
                    }
                    st.toast(f"âœ… å·²ç¼“å­˜: {excel_file.name} (å…± {len(words)} è¯)")

    with st.expander("â• æ‰‹åŠ¨æ·»åŠ "):
        manual_name = st.text_input("è¯åº“å")
        manual_text = st.text_area("å•è¯åˆ—è¡¨")
        if st.button("æ·»åŠ "):
            if manual_name and manual_text:
                words = [w.strip() for w in manual_text.replace('\n', ',').split(',') if w.strip()]
                st.session_state['word_libraries'][manual_name] = {
                    'words': words,
                    'default_color': '#00FF00'
                }
                st.rerun()

    st.divider()

    st.subheader("3. é¢œè‰²é…ç½®")
    final_configs = {}

    if st.session_state['word_libraries']:
        all_libs = list(st.session_state['word_libraries'].keys())
        selected = st.multiselect("é€‰æ‹©è¯åº“", all_libs, default=all_libs)

        if selected:
            for name in selected:
                col1, col2 = st.columns([3, 1])
                with col1:
                    count = len(st.session_state['word_libraries'][name]['words'])
                    st.caption(f"**{name}** ({count} è¯)")
                with col2:
                    c = st.color_picker(f"C-{name}", st.session_state['word_libraries'][name]['default_color'],
                                        key=f"c_{name}")

                final_configs[name] = {
                    'words': st.session_state['word_libraries'][name]['words'],
                    'rgb': hex_to_rgb(c)
                }

    st.divider()
    process_btn = st.button("ğŸš€ å¼€å§‹ç²¾å‡†åŒ¹é…", type="primary", use_container_width=True)
    if st.button("ğŸ—‘ï¸ æ¸…é™¤ç¼“å­˜"):
        st.session_state['word_libraries'] = {}
        st.cache_data.clear()
        st.rerun()

# --- ä¸»ç•Œé¢ ---
st.title("ğŸ¯ PDF å…¨è¯åŒ¹é…é«˜äº®å·¥å…·")
st.markdown("å·²å¯ç”¨ **Whole Word Matching** æ¨¡å¼ï¼šç²¾ç¡®åŒ¹é…å•è¯ï¼Œæ‹’ç»éƒ¨åˆ†åŒ¹é…ã€‚")

if process_btn and uploaded_pdf and final_configs:

    progress_bar = st.progress(0)
    status_text = st.empty()

    try:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_input:
            tmp_input.write(uploaded_pdf.getvalue())
            tmp_input_path = tmp_input.name

        doc = fitz.open(tmp_input_path)
        total_pages = len(doc)
        total_stats = {name: 0 for name in final_configs}

        status_text.text("ğŸ” æ­£åœ¨åˆå§‹åŒ–ç²¾å‡†åŒ¹é…å¼•æ“...")

        # --- é¢„å¤„ç†è¯åº“ï¼šåŒºåˆ†å•è¯å’ŒçŸ­è¯­ ---
        # å•è¯ï¼šç”¨ get_text("words") åšå…¨ç­‰åŒ¹é… (è§£å†³ cat åŒ¹é… scatter)
        # çŸ­è¯­ï¼šç”¨ search_for åšæœç´¢åŒ¹é… (è§£å†³ Deep Learning å¸¦ç©ºæ ¼é—®é¢˜)
        processed_configs = {}
        for name, config in final_configs.items():
            words_list = config['words']
            single_words = set()  # ç”¨é›†åˆåŠ é€ŸæŸ¥æ‰¾
            phrases = []

            for w in words_list:
                clean_w = w.strip()
                if " " in clean_w:  # å¦‚æœåŒ…å«ç©ºæ ¼ï¼Œè§†ä¸ºçŸ­è¯­
                    phrases.append(clean_w)
                else:
                    single_words.add(clean_w.lower())  # è½¬å°å†™å­˜å…¥é›†åˆ

            processed_configs[name] = {
                'singles': single_words,
                'phrases': phrases,
                'color': config['rgb']
            }

        # --- æ ¸å¿ƒå¾ªç¯ ---
        for i, page in enumerate(doc):
            if i % 5 == 0:
                progress_bar.progress((i + 1) / total_pages)
                status_text.text(f"æ­£åœ¨åˆ†æç¬¬ {i + 1} / {total_pages} é¡µ...")

            # 1. å¤„ç†æ‰€æœ‰â€œå•ä¸ªå•è¯â€ (å…¨è¯åŒ¹é…é€»è¾‘)
            # è·å–é¡µé¢æ‰€æœ‰å•è¯: (x0, y0, x1, y1, "word_string", ...)
            page_words = page.get_text("words")

            for w_info in page_words:
                # w_info[4] æ˜¯å•è¯æ–‡æœ¬
                current_word_text = w_info[4].lower()
                current_word_rect = fitz.Rect(w_info[0], w_info[1], w_info[2], w_info[3])

                # æ£€æŸ¥è¿™ä¸ªå•è¯æ˜¯å¦åœ¨æˆ‘ä»¬çš„ä»»ä½•ä¸€ä¸ªè¯åº“é‡Œ
                for lib_name, p_cfg in processed_configs.items():
                    if current_word_text in p_cfg['singles']:
                        # åªæœ‰å®Œå…¨ç›¸ç­‰æ‰é«˜äº®
                        annot = page.add_highlight_annot(current_word_rect)
                        annot.set_colors(stroke=p_cfg['color'])
                        annot.update()
                        total_stats[lib_name] += 1

            # 2. å¤„ç†â€œçŸ­è¯­â€ (ä¼ ç»Ÿæœç´¢é€»è¾‘ï¼Œå› ä¸º get_text("words") ä¼šæŠŠçŸ­è¯­æ‹†æ•£)
            for lib_name, p_cfg in processed_configs.items():
                for phrase in p_cfg['phrases']:
                    # çŸ­è¯­ä¾ç„¶ä½¿ç”¨ search_forï¼Œä½†é€šå¸¸çŸ­è¯­ä¸å¤ªå®¹æ˜“å‡ºç°è¯¯åŒ¹é…
                    quads = page.search_for(phrase, quads=True)
                    if quads:
                        for quad in quads:
                            annot = page.add_highlight_annot(quad)
                            annot.set_colors(stroke=p_cfg['color'])
                            annot.update()
                            total_stats[lib_name] += 1

        # ä¿å­˜
        status_text.text("ğŸ’¾ æ­£åœ¨ä¿å­˜...")
        output_path = tmp_input_path.replace(".pdf", "_highlighted.pdf")
        doc.save(output_path, garbage=4, deflate=True)
        doc.close()

        progress_bar.progress(100)
        status_text.text("âœ… å®Œæˆï¼")

        # ç»Ÿè®¡
        cols = st.columns(len(total_stats))
        for idx, (name, count) in enumerate(total_stats.items()):
            cols[idx].metric(label=name, value=count)

        # ä»…æ˜¾ç¤ºä¸‹è½½æŒ‰é’®ï¼Œæ— é¢„è§ˆ
        with open(output_path, "rb") as file:
            st.download_button(
                "ğŸ“¥ ä¸‹è½½ç»“æœ PDF",
                data=file,
                file_name=f"WholeWord_{uploaded_pdf.name}",
                mime="application/pdf",
                type="primary"  # é†’ç›®çš„æŒ‰é’®
            )

        os.unlink(tmp_input_path)
        os.unlink(output_path)
        gc.collect()

    except Exception as e:
        st.error(f"å‡ºé”™: {e}")

elif process_btn:
    st.error("è¯·æ£€æŸ¥é…ç½®ã€‚")