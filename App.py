import streamlit as st
import fitz  # PyMuPDF
import pandas as pd
import tempfile
import os
import gc
import nltk
from nltk.stem import SnowballStemmer

# --- é¡µé¢é…ç½® ---
st.set_page_config(page_title="PDF æ™ºèƒ½è¯åº“é«˜äº®å·¥å…·", page_icon="ğŸ“š", layout="wide")

# --- NLTK åˆå§‹åŒ– ---
try:
    stemmer = SnowballStemmer("english")
except:
    nltk.download('snowball_data')
    stemmer = SnowballStemmer("english")


# --- ç¼“å­˜å‡½æ•° ---
@st.cache_data(ttl=3600)
def load_excel_data(file):
    try:
        df = pd.read_excel(file)
        return df.iloc[:, 0].dropna().astype(str).str.strip().unique().tolist()
    except Exception:
        return []


# --- é¢œè‰²å¤„ç†å‡½æ•° ---
def hex_to_rgb(hex_color):
    hex_color = hex_color.lstrip('#')
    return tuple(int(hex_color[i:i + 2], 16) / 255.0 for i in (0, 2, 4))


def get_lighter_color(rgb, factor):
    r, g, b = rgb
    new_r = r + (1 - r) * factor
    new_g = g + (1 - g) * factor
    new_b = b + (1 - b) * factor
    return (new_r, new_g, new_b)


# --- åˆå§‹åŒ– Session State ---
if 'word_libraries' not in st.session_state:
    st.session_state['word_libraries'] = {}

if 'opacity_value' not in st.session_state:
    st.session_state['opacity_value'] = 0.20


# --- å›è°ƒå‡½æ•° ---
def update_opacity_from_slider():
    st.session_state['opacity_value'] = st.session_state['slider_widget']


def update_opacity_from_input():
    st.session_state['opacity_value'] = st.session_state['input_widget']


# --- ä¾§è¾¹æ  UI ---
with st.sidebar:
    st.title("ğŸŒŸ æ•ˆæœè®¾ç½®")

    st.subheader("1. æ–‡ä»¶")
    uploaded_pdf = st.file_uploader("ä¸Šä¼  PDF", type=["pdf"], label_visibility="collapsed")

    st.divider()

    st.subheader("2. è¯åº“ï¼ˆExcelï¼‰")
    uploaded_excels = st.file_uploader("ä¸Šä¼ è¯åº“ï¼ˆå•è¯æ”¾åœ¨è¡¨æ ¼ç¬¬ä¸€åˆ—ï¼‰", type=['xlsx'], accept_multiple_files=True)

    if uploaded_excels:
        for excel_file in uploaded_excels:
            if excel_file.name not in st.session_state['word_libraries']:
                words = load_excel_data(excel_file)
                if words:
                    st.session_state['word_libraries'][excel_file.name] = {
                        'words': words,
                        'default_color': '#FFFF00'
                    }
                    st.toast(f"âœ… å·²ç¼“å­˜: {excel_file.name} (å…± {len(words)} è¯)")

    with st.expander("â• æ‰‹åŠ¨æ·»åŠ "):
        manual_name = st.text_input("è¯åº“å")
        manual_text = st.text_area("å•è¯åˆ—è¡¨")
        if st.button("æ·»åŠ "):
            if manual_name and manual_text:
                words = [w.strip() for w in manual_text.replace('\n', ',').split(',') if w.strip()]
                st.session_state['word_libraries'][manual_name] = {
                    'words': words,
                    'default_color': '#FFFF00'
                }
                st.rerun()

    st.divider()

    st.subheader("3. åŒ¹é…ä¸è§†è§‰")
    use_stemming = st.checkbox("å¯ç”¨æ™ºèƒ½è¯å½¢åŒ¹é… (Stemming)", value=True)

    # --- ç´¢å¼•é¡µé«˜çº§è®¾ç½® ---
    generate_index = st.checkbox("ç”Ÿæˆæ–‡æœ«å•è¯ç´¢å¼• (Index Page)", value=True)

    # åªæœ‰å‹¾é€‰äº†æ‰æ˜¾ç¤ºè¯¦ç»†è®¾ç½®
    idx_col_count = 4
    idx_font_size = 10
    index_target_libs = []  # åˆå§‹åŒ–

    if generate_index:
        col1, col2 = st.columns(2)
        with col1:
            idx_col_count = st.selectbox("æ’ç‰ˆåˆ—æ•°", [1, 2, 3, 4], index=3)  # é»˜è®¤4åˆ—
        with col2:
            idx_font_size = st.number_input("ç´¢å¼•å­—å·", min_value=8, max_value=16, value=10, step=1)

        # ã€ä¿®æ”¹ç‚¹ 1ã€‘æ–°å¢ï¼šé€‰æ‹©è¦åŒ…å«åœ¨ç´¢å¼•ä¸­çš„å…·ä½“è¯åº“
        available_libs = list(st.session_state['word_libraries'].keys())
        st.caption("é€‰æ‹©è¦åŒ…å«åœ¨ç´¢å¼•é¡µä¸­çš„è¯åº“ï¼š")
        index_target_libs = st.multiselect(
            "ç´¢å¼•è¯åº“é€‰æ‹©",
            options=available_libs,
            default=available_libs,
            label_visibility="collapsed",
            help="æœªè¢«é€‰ä¸­çš„è¯åº“å°†åªä¼šè¢«é«˜äº®ï¼Œè€Œä¸ä¼šå‡ºç°åœ¨æ–‡æœ«çš„å•è¯åˆ—è¡¨é‡Œã€‚"
        )

    st.write("é‡å¤å•è¯é«˜äº®é€æ˜åº¦ (1.0=åŸè‰², 0.0=é€æ˜)")

    col_input, col_slider = st.columns([1, 2.5])

    with col_input:
        st.number_input(
            label="æ•°å€¼è¾“å…¥",
            label_visibility="collapsed",
            min_value=0.0,
            max_value=1.0,
            step=0.01,
            value=st.session_state['opacity_value'],
            key='input_widget',
            on_change=update_opacity_from_input,
            format="%.2f"
        )

    with col_slider:
        st.slider(
            label="æ»‘å—è°ƒèŠ‚",
            label_visibility="collapsed",
            min_value=0.0,
            max_value=1.0,
            step=0.01,
            value=st.session_state['opacity_value'],
            key='slider_widget',
            on_change=update_opacity_from_slider,
            help="1.00 è¡¨ç¤ºä¿æŒæœ€æ·±çš„åŸè‰²ï¼Œ0.00 è¡¨ç¤ºå®Œå…¨é€æ˜ï¼ˆç™½è‰²ï¼‰ã€‚"
        )

    repeat_opacity = st.session_state['opacity_value']

    final_configs = {}

    if st.session_state['word_libraries']:
        all_libs = list(st.session_state['word_libraries'].keys())
        selected = st.multiselect("é€‰æ‹©é«˜äº®è¯åº“", all_libs, default=all_libs)

        if selected:
            for name in selected:
                col1, col2 = st.columns([3, 1])
                with col1:
                    count = len(st.session_state['word_libraries'][name]['words'])
                    st.caption(f"**{name}** ({count} è¯)")
                with col2:
                    c = st.color_picker(f"C-{name}", st.session_state['word_libraries'][name]['default_color'],
                                        key=f"c_{name}")

                final_configs[name] = {
                    'words': st.session_state['word_libraries'][name]['words'],
                    'rgb': hex_to_rgb(c)
                }

    st.divider()
    process_btn = st.button("ğŸš€ ç”Ÿæˆé«˜äº®æ–‡ä»¶", type="primary", use_container_width=True)
    if st.button("ğŸ—‘ï¸ æ¸…é™¤ç¼“å­˜"):
        st.session_state['word_libraries'] = {}
        st.cache_data.clear()
        st.rerun()

# --- ä¸»ç•Œé¢ ---
st.title("ğŸ“š PDF æ™ºèƒ½è¯åº“é«˜äº®å·¥å…·")

if use_stemming:
    st.success("âœ¨ æ™ºèƒ½æ¨¡å¼å·²å¼€å¯ï¼šå°†è‡ªåŠ¨å¿½ç•¥å•è¯çš„æ—¶æ€ã€å¤æ•°å’Œå˜å½¢ã€‚")
else:
    st.info("ğŸ”’ ç²¾ç¡®æ¨¡å¼ï¼šä»…åŒ¹é…å®Œå…¨ä¸€è‡´çš„å•è¯ã€‚")

st.markdown(
    "Tipï¼š**é¦–æ¬¡**å‡ºç°çš„å•è¯ä½¿ç”¨**æ·±è‰²**ï¼Œ**é‡å¤**å‡ºç°çš„å•è¯è‡ªåŠ¨æŒ‰**é€æ˜åº¦**å˜æµ…ï¼›é€‰æ‹©ç”Ÿæˆæ–‡æœ«å•è¯ç´¢å¼•ï¼Œå°†åœ¨æ–‡æœ«é™„ä¸Š**é«˜äº®å•è¯åˆ—è¡¨**ï¼ˆå­—æ¯é¡ºåºï¼‰ã€‚")

if process_btn and uploaded_pdf and final_configs:

    progress_bar = st.progress(0)
    status_text = st.empty()

    try:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_input:
            tmp_input.write(uploaded_pdf.getvalue())
            tmp_input_path = tmp_input.name

        doc = fitz.open(tmp_input_path)
        total_pages = len(doc)
        total_stats = {name: 0 for name in final_configs}

        status_text.text("ğŸ” æ­£åœ¨åˆå§‹åŒ–...")

        # --- é¢„å¤„ç†é…ç½® ---
        processed_configs = {}
        whiteness_factor = 1.0 - repeat_opacity

        for name, config in final_configs.items():
            words_list = config['words']
            singles_stems = set()
            singles_exact = set()
            phrases = []

            # åå‘æ˜ å°„å­—å…¸
            stem_to_origin_map = {}
            exact_to_origin_map = {}

            for w in words_list:
                clean_w = w.strip()
                if " " in clean_w:
                    phrases.append(clean_w)
                else:
                    lower_w = clean_w.lower()
                    singles_exact.add(lower_w)
                    exact_to_origin_map[lower_w] = clean_w

                    if use_stemming:
                        stem_w = stemmer.stem(lower_w)
                        singles_stems.add(stem_w)
                        stem_to_origin_map[stem_w] = clean_w

            base_rgb = config['rgb']
            light_rgb = get_lighter_color(base_rgb, factor=whiteness_factor)

            processed_configs[name] = {
                'singles_stems': singles_stems,
                'singles_exact': singles_exact,
                'phrases': phrases,
                'base_color': base_rgb,
                'light_color': light_rgb,
                'stem_map': stem_to_origin_map,
                'exact_map': exact_to_origin_map
            }

        # --- è¿½è¸ªè®°å½•å™¨ ---
        global_seen_items = {name: set() for name in final_configs}

        # æŒ‰è¯åº“åˆ†ç±»æ”¶é›†
        index_data_by_lib = {name: set() for name in final_configs}

        # --- æ ¸å¿ƒå¾ªç¯ ---
        for i, page in enumerate(doc):
            if i % 5 == 0:
                progress_bar.progress((i + 1) / total_pages)
                status_text.text(f"æ­£åœ¨åˆ†æç¬¬ {i + 1} / {total_pages} é¡µ...")

            # 1. å¤„ç†å•ä¸ªå•è¯
            page_words = page.get_text("words")

            for w_info in page_words:
                current_text = w_info[4].lower()
                current_rect = fitz.Rect(w_info[0], w_info[1], w_info[2], w_info[3])
                current_stem = stemmer.stem(current_text) if use_stemming else None

                for lib_name, p_cfg in processed_configs.items():
                    matched = False
                    match_key = None
                    origin_word = None  # ç”¨äºç´¢å¼•

                    if use_stemming:
                        if current_stem in p_cfg['singles_stems']:
                            matched = True
                            match_key = current_stem
                            origin_word = p_cfg['stem_map'].get(current_stem)
                    else:
                        if current_text in p_cfg['singles_exact']:
                            matched = True
                            match_key = current_text
                            origin_word = p_cfg['exact_map'].get(current_text)

                    if matched:
                        if match_key not in global_seen_items[lib_name]:
                            use_color = p_cfg['base_color']
                            global_seen_items[lib_name].add(match_key)
                        else:
                            use_color = p_cfg['light_color']

                        if origin_word:
                            index_data_by_lib[lib_name].add(origin_word)

                        annot = page.add_highlight_annot(current_rect)
                        annot.set_colors(stroke=use_color)
                        annot.update()
                        total_stats[lib_name] += 1

            # 2. å¤„ç†çŸ­è¯­
            for lib_name, p_cfg in processed_configs.items():
                for phrase in p_cfg['phrases']:
                    quads_list = page.search_for(phrase, quads=True)
                    if quads_list:
                        for quad in quads_list:
                            match_key = phrase.lower()

                            if match_key not in global_seen_items[lib_name]:
                                use_color = p_cfg['base_color']
                                global_seen_items[lib_name].add(match_key)
                            else:
                                use_color = p_cfg['light_color']

                            index_data_by_lib[lib_name].add(phrase)

                            annot = page.add_highlight_annot(quad)
                            annot.set_colors(stroke=use_color)
                            annot.update()
                            total_stats[lib_name] += 1

        # --- åŠ¨æ€ç´¢å¼•æ’ç‰ˆé€»è¾‘ ---
        if generate_index:
            # ã€ä¿®æ”¹ç‚¹ 2ã€‘è¿‡æ»¤æ•°æ®ï¼šåªä¿ç•™ç”¨æˆ·å‹¾é€‰è¦ç´¢å¼•çš„è¯åº“
            final_index_data = {
                k: v for k, v in index_data_by_lib.items()
                if k in index_target_libs
            }

            has_any_words = any(len(words) > 0 for words in final_index_data.values())

            if has_any_words:
                status_text.text(f"ğŸ“„ æ­£åœ¨æ’ç‰ˆç´¢å¼•é¡µ ({idx_col_count}æ )...")

                idx_page = doc.new_page()
                page_width = idx_page.rect.width
                page_height = idx_page.rect.height

                # --- åŠ¨æ€è®¡ç®—æ’ç‰ˆå‚æ•° ---
                margin_x = 40
                margin_y = 50
                col_gap = 15
                col_count = idx_col_count

                # æ ¹æ®åˆ—æ•°è®¡ç®—åˆ—å®½
                col_width = (page_width - 2 * margin_x - (col_count - 1) * col_gap) / col_count

                # æ ¹æ®å­—å·è®¡ç®—è¡Œé«˜å’Œæ ‡é¢˜é«˜
                line_height = idx_font_size * 1.5  # è¡Œé«˜é€šå¸¸æ˜¯å­—å·çš„ 1.5 å€
                header_height = idx_font_size * 2.0
                title_font_size = idx_font_size + 8  # æ€»æ ‡é¢˜æ¯”å†…å®¹å¤§ä¸€äº›
                lib_title_font_size = idx_font_size + 2  # è¯åº“æ ‡é¢˜æ¯”å†…å®¹å¤§ä¸€ç‚¹

                # åŠ¨æ€è®¡ç®—å•è¯æˆªæ–­é•¿åº¦
                avg_char_width = idx_font_size * 0.55
                truncation_limit = int(col_width / avg_char_width) - 2
                if truncation_limit < 5: truncation_limit = 5

                current_col = 0
                current_y = margin_y

                idx_page.insert_text((margin_x, 30), "Index of Words", fontsize=title_font_size, color=(0, 0, 0))

                # éå†è¿‡æ»¤åçš„æ•°æ®
                for lib_name, words_set in final_index_data.items():
                    if not words_set:
                        continue

                    sorted_words = sorted(list(words_set), key=str.lower)
                    lib_color = final_configs[lib_name]['rgb']

                    needed_height = header_height + line_height
                    if current_y + needed_height > page_height - margin_y:
                        current_col += 1
                        current_y = margin_y
                        if current_col >= col_count:
                            idx_page = doc.new_page()
                            current_col = 0

                    current_x = margin_x + current_col * (col_width + col_gap)

                    # ç»˜åˆ¶è¯åº“æ ‡é¢˜
                    idx_page.insert_text((current_x, current_y), f"â–  {lib_name}", fontsize=lib_title_font_size,
                                         color=lib_color)
                    current_y += header_height

                    for word in sorted_words:
                        if current_y > page_height - margin_y:
                            current_col += 1
                            current_y = margin_y
                            if current_col >= col_count:
                                idx_page = doc.new_page()
                                current_col = 0

                            current_x = margin_x + current_col * (col_width + col_gap)

                        # åŠ¨æ€æˆªæ–­
                        display_word = word if len(word) < truncation_limit else word[:truncation_limit] + "..."
                        idx_page.insert_text((current_x, current_y), f"  {display_word}", fontsize=idx_font_size,
                                             color=(0.2, 0.2, 0.2))
                        current_y += line_height

                    current_y += line_height / 2

        # ä¿å­˜ä¸ç»“æŸ
        status_text.text("ğŸ’¾ æ­£åœ¨æ¸²æŸ“æœ€ç»ˆæ–‡ä»¶...")
        output_path = tmp_input_path.replace(".pdf", "_highlighted_index.pdf")
        doc.save(output_path, garbage=4, deflate=True)
        doc.close()

        progress_bar.progress(100)
        status_text.text("âœ… å®Œæˆï¼")

        cols = st.columns(len(total_stats))
        for idx, (name, count) in enumerate(total_stats.items()):
            cols[idx].metric(label=name, value=count)

        with open(output_path, "rb") as file:
            st.download_button(
                "ğŸ“¥ ä¸‹è½½ç»“æœ PDF",
                data=file,
                file_name=f"Highlight_{uploaded_pdf.name}",
                mime="application/pdf",
                type="primary"
            )

        os.unlink(tmp_input_path)
        os.unlink(output_path)
        gc.collect()

    except Exception as e:
        st.error(f"å‡ºé”™: {e}")

elif process_btn:
    st.error("è¯·æ£€æŸ¥é…ç½®ã€‚")