import streamlit as st
import fitz  # PyMuPDF
import pandas as pd
import tempfile
import os
import gc
import nltk
import base64  # ç”¨äºPDFé¢„è§ˆç¼–ç 
from nltk.stem import SnowballStemmer

# --- é¡µé¢é…ç½® ---
st.set_page_config(page_title="PDF æ™ºèƒ½è¯åº“é«˜äº®å·¥å…·", page_icon="ğŸ“š", layout="wide")

# --- NLTK åˆå§‹åŒ– ---
try:
    stemmer = SnowballStemmer("english")
except:
    nltk.download('snowball_data')
    stemmer = SnowballStemmer("english")


# --- ç¼“å­˜å‡½æ•° ---
@st.cache_data(ttl=3600)
def load_excel_data(file):
    try:
        df = pd.read_excel(file)
        return df.iloc[:, 0].dropna().astype(str).str.strip().unique().tolist()
    except Exception:
        return []


# --- é¢œè‰²å¤„ç†å‡½æ•° ---
def hex_to_rgb(hex_color):
    hex_color = hex_color.lstrip('#')
    return tuple(int(hex_color[i:i + 2], 16) / 255.0 for i in (0, 2, 4))


def get_lighter_color(rgb, factor):
    r, g, b = rgb
    new_r = r + (1 - r) * factor
    new_g = g + (1 - g) * factor
    new_b = b + (1 - b) * factor
    return (new_r, new_g, new_b)


# --- åˆå§‹åŒ– Session State ---
if 'word_libraries' not in st.session_state:
    st.session_state['word_libraries'] = {}

if 'opacity_value' not in st.session_state:
    st.session_state['opacity_value'] = 0.20


# --- å›è°ƒå‡½æ•° ---
def update_opacity_from_slider():
    st.session_state['opacity_value'] = st.session_state['slider_widget']


def update_opacity_from_input():
    st.session_state['opacity_value'] = st.session_state['input_widget']


# --- ä¾§è¾¹æ  UI ---
with st.sidebar:
    st.title("ğŸŒŸ æ•ˆæœè®¾ç½®")

    st.subheader("1. æ–‡ä»¶")
    uploaded_pdf = st.file_uploader("ä¸Šä¼  PDF", type=["pdf"], label_visibility="collapsed")

    st.divider()

    st.subheader("2. è¯åº“ï¼ˆExcelï¼‰")
    uploaded_excels = st.file_uploader("ä¸Šä¼ è¯åº“ï¼ˆå•è¯æ”¾åœ¨è¡¨æ ¼ç¬¬ä¸€åˆ—ï¼‰", type=['xlsx'], accept_multiple_files=True)

    if uploaded_excels:
        for excel_file in uploaded_excels:
            if excel_file.name not in st.session_state['word_libraries']:
                words = load_excel_data(excel_file)
                if words:
                    st.session_state['word_libraries'][excel_file.name] = {
                        'words': words,
                        'default_color': '#FFFF00'
                    }
                    st.toast(f"âœ… å·²ç¼“å­˜: {excel_file.name} (å…± {len(words)} è¯)")

    with st.expander("â• æ‰‹åŠ¨æ·»åŠ "):
        manual_name = st.text_input("è¯åº“å")
        manual_text = st.text_area("å•è¯åˆ—è¡¨")
        if st.button("æ·»åŠ "):
            if manual_name and manual_text:
                words = [w.strip() for w in manual_text.replace('\n', ',').split(',') if w.strip()]
                st.session_state['word_libraries'][manual_name] = {
                    'words': words,
                    'default_color': '#FFFF00'
                }
                st.rerun()

    st.divider()

    st.subheader("3. åŒ¹é…ä¸è§†è§‰")
    use_stemming = st.checkbox("å¯ç”¨æ™ºèƒ½è¯å½¢åŒ¹é… (Stemming)", value=True)

    # --- ç´¢å¼•é¡µé«˜çº§è®¾ç½® ---
    generate_index = st.checkbox("ç”Ÿæˆæ–‡æœ«å•è¯ç´¢å¼• (Index Page)", value=True)

    # é»˜è®¤å€¼åˆå§‹åŒ–
    idx_col_count = 4
    idx_font_size = 10
    index_target_libs = []
    show_variants = False

    if generate_index:
        # é€»è¾‘ä¼˜åŒ–ï¼šåªæœ‰å¼€å¯ Stemming æ‰è¯¢é—®æ˜¯å¦æ˜¾ç¤ºå˜ä½“
        if use_stemming:
            show_variants = st.checkbox("åœ¨ç´¢å¼•ä¸­æ˜¾ç¤ºæ–‡å†…å•è¯å˜ä½“ (ä¾‹å¦‚: run -> running, ran)", value=True)
        else:
            show_variants = False  # ç²¾ç¡®åŒ¹é…æ²¡æœ‰å˜ä½“ï¼Œå¼ºåˆ¶ä¸ºFalse

        # åŠ¨æ€è®¾ç½®é»˜è®¤åˆ—æ•°ç´¢å¼•
        default_col_index = 1 if show_variants else 3

        col1, col2 = st.columns(2)
        with col1:
            idx_col_count = st.selectbox("æ’ç‰ˆåˆ—æ•°", [1, 2, 3, 4], index=default_col_index)
        with col2:
            idx_font_size = st.number_input("ç´¢å¼•å­—å·", min_value=8, max_value=16, value=10, step=1)

        available_libs = list(st.session_state['word_libraries'].keys())
        st.caption("é€‰æ‹©è¦åŒ…å«åœ¨ç´¢å¼•é¡µä¸­çš„è¯åº“ï¼š")
        index_target_libs = st.multiselect(
            "ç´¢å¼•è¯åº“é€‰æ‹©",
            options=available_libs,
            default=available_libs,
            label_visibility="collapsed"
        )

    st.write("é‡å¤å•è¯é«˜äº®é€æ˜åº¦ (1.0=åŸè‰², 0.0=é€æ˜)")

    col_input, col_slider = st.columns([1, 2.5])

    with col_input:
        st.number_input(
            label="æ•°å€¼è¾“å…¥",
            label_visibility="collapsed",
            min_value=0.0,
            max_value=1.0,
            step=0.01,
            value=st.session_state['opacity_value'],
            key='input_widget',
            on_change=update_opacity_from_input,
            format="%.2f"
        )

    with col_slider:
        st.slider(
            label="æ»‘å—è°ƒèŠ‚",
            label_visibility="collapsed",
            min_value=0.0,
            max_value=1.0,
            step=0.01,
            value=st.session_state['opacity_value'],
            key='slider_widget',
            on_change=update_opacity_from_slider,
            help="1.00 è¡¨ç¤ºä¿æŒæœ€æ·±çš„åŸè‰²ï¼Œ0.00 è¡¨ç¤ºå®Œå…¨é€æ˜ï¼ˆç™½è‰²ï¼‰ã€‚"
        )

    repeat_opacity = st.session_state['opacity_value']

    final_configs = {}

    if st.session_state['word_libraries']:
        all_libs = list(st.session_state['word_libraries'].keys())
        selected = st.multiselect("é€‰æ‹©é«˜äº®è¯åº“", all_libs, default=all_libs)

        if selected:
            for name in selected:
                col1, col2 = st.columns([3, 1])
                with col1:
                    count = len(st.session_state['word_libraries'][name]['words'])
                    st.caption(f"**{name}** ({count} è¯)")
                with col2:
                    c = st.color_picker(f"C-{name}", st.session_state['word_libraries'][name]['default_color'],
                                        key=f"c_{name}")

                final_configs[name] = {
                    'words': st.session_state['word_libraries'][name]['words'],
                    'rgb': hex_to_rgb(c)
                }

    st.divider()
    process_btn = st.button("ğŸš€ ç”Ÿæˆé«˜äº®æ–‡ä»¶", type="primary", use_container_width=True)
    if st.button("ğŸ—‘ï¸ æ¸…é™¤ç¼“å­˜"):
        st.session_state['word_libraries'] = {}
        st.cache_data.clear()
        st.rerun()

# --- ä¸»ç•Œé¢ ---
st.title("ğŸ“š PDF æ™ºèƒ½è¯åº“é«˜äº®å·¥å…·")

if use_stemming:
    st.success("âœ¨ æ™ºèƒ½æ¨¡å¼å·²å¼€å¯ï¼šå°†è‡ªåŠ¨å¿½ç•¥å•è¯çš„æ—¶æ€ã€å¤æ•°å’Œå˜å½¢ã€‚")
else:
    st.info("ğŸ”’ ç²¾ç¡®æ¨¡å¼ï¼šä»…åŒ¹é…å®Œå…¨ä¸€è‡´çš„å•è¯ã€‚")

st.markdown(
    "Tipï¼š**é¦–æ¬¡**å‡ºç°çš„å•è¯ä½¿ç”¨**æ·±è‰²**ï¼Œ**é‡å¤**å‡ºç°çš„å•è¯è‡ªåŠ¨æŒ‰**é€æ˜åº¦**å˜æµ…ï¼›é€‰æ‹©ç”Ÿæˆæ–‡æœ«å•è¯ç´¢å¼•ï¼Œå°†åœ¨æ–‡æœ«é™„ä¸Šé«˜äº®å•è¯åˆ—è¡¨ã€‚")

if process_btn and uploaded_pdf and final_configs:

    progress_bar = st.progress(0)
    status_text = st.empty()

    try:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_input:
            tmp_input.write(uploaded_pdf.getvalue())
            tmp_input_path = tmp_input.name

        doc = fitz.open(tmp_input_path)
        total_pages = len(doc)
        total_stats = {name: 0 for name in final_configs}

        status_text.text("ğŸ” æ­£åœ¨åˆå§‹åŒ–...")

        # --- é¢„å¤„ç†é…ç½® ---
        processed_configs = {}
        whiteness_factor = 1.0 - repeat_opacity

        for name, config in final_configs.items():
            words_list = config['words']
            singles_stems = set()
            singles_exact = set()
            phrases = []

            # åå‘æ˜ å°„å­—å…¸
            stem_to_origin_map = {}
            exact_to_origin_map = {}

            for w in words_list:
                clean_w = w.strip()
                if " " in clean_w:
                    phrases.append(clean_w)
                else:
                    lower_w = clean_w.lower()
                    singles_exact.add(lower_w)
                    exact_to_origin_map[lower_w] = clean_w

                    if use_stemming:
                        stem_w = stemmer.stem(lower_w)
                        singles_stems.add(stem_w)
                        stem_to_origin_map[stem_w] = clean_w

            base_rgb = config['rgb']
            light_rgb = get_lighter_color(base_rgb, factor=whiteness_factor)

            processed_configs[name] = {
                'singles_stems': singles_stems,
                'singles_exact': singles_exact,
                'phrases': phrases,
                'base_color': base_rgb,
                'light_color': light_rgb,
                'stem_map': stem_to_origin_map,
                'exact_map': exact_to_origin_map
            }

        # --- è¿½è¸ªè®°å½•å™¨ ---
        global_seen_items = {name: set() for name in final_configs}

        # {è¯åº“å: {è¯åº“åŸè¯: {PDFå®é™…å‡ºç°çš„å•è¯é›†åˆ}}}
        index_data_by_lib = {name: {} for name in final_configs}

        # --- æ ¸å¿ƒå¾ªç¯ ---
        for i, page in enumerate(doc):
            if i % 5 == 0:
                progress_bar.progress((i + 1) / total_pages)
                status_text.text(f"æ­£åœ¨åˆ†æç¬¬ {i + 1} / {total_pages} é¡µ...")

            # 1. å¤„ç†å•ä¸ªå•è¯
            page_words = page.get_text("words")

            for w_info in page_words:
                current_text = w_info[4]  # PDFä¸­çš„å®é™…å•è¯
                current_text_lower = current_text.lower()
                current_rect = fitz.Rect(w_info[0], w_info[1], w_info[2], w_info[3])
                current_stem = stemmer.stem(current_text_lower) if use_stemming else None

                for lib_name, p_cfg in processed_configs.items():
                    matched = False
                    match_key = None
                    origin_word = None  # è¯åº“ä¸­çš„åŸè¯

                    if use_stemming:
                        if current_stem in p_cfg['singles_stems']:
                            matched = True
                            match_key = current_stem
                            origin_word = p_cfg['stem_map'].get(current_stem)
                    else:
                        if current_text_lower in p_cfg['singles_exact']:
                            matched = True
                            match_key = current_text_lower
                            origin_word = p_cfg['exact_map'].get(current_text_lower)

                    if matched:
                        if match_key not in global_seen_items[lib_name]:
                            use_color = p_cfg['base_color']
                            global_seen_items[lib_name].add(match_key)
                        else:
                            use_color = p_cfg['light_color']

                        if origin_word:
                            if origin_word not in index_data_by_lib[lib_name]:
                                index_data_by_lib[lib_name][origin_word] = set()
                            index_data_by_lib[lib_name][origin_word].add(current_text)

                        annot = page.add_highlight_annot(current_rect)
                        annot.set_colors(stroke=use_color)
                        annot.update()
                        total_stats[lib_name] += 1

            # 2. å¤„ç†çŸ­è¯­
            for lib_name, p_cfg in processed_configs.items():
                for phrase in p_cfg['phrases']:
                    quads_list = page.search_for(phrase, quads=True)
                    if quads_list:
                        for quad in quads_list:
                            match_key = phrase.lower()

                            if match_key not in global_seen_items[lib_name]:
                                use_color = p_cfg['base_color']
                                global_seen_items[lib_name].add(match_key)
                            else:
                                use_color = p_cfg['light_color']

                            if phrase not in index_data_by_lib[lib_name]:
                                index_data_by_lib[lib_name][phrase] = set()
                            index_data_by_lib[lib_name][phrase].add(phrase)

                            annot = page.add_highlight_annot(quad)
                            annot.set_colors(stroke=use_color)
                            annot.update()
                            total_stats[lib_name] += 1

        # --- åŠ¨æ€ç´¢å¼•æ’ç‰ˆé€»è¾‘ ---
        if generate_index:
            # è¿‡æ»¤æ•°æ®
            final_index_data = {
                k: v for k, v in index_data_by_lib.items()
                if k in index_target_libs
            }

            has_any_words = any(len(words_dict) > 0 for words_dict in final_index_data.values())

            if has_any_words:
                status_text.text(f"ğŸ“„ æ­£åœ¨æ’ç‰ˆç´¢å¼•é¡µ ({idx_col_count}æ )...")

                idx_page = doc.new_page()
                page_width = idx_page.rect.width
                page_height = idx_page.rect.height

                # --- åŠ¨æ€è®¡ç®—æ’ç‰ˆå‚æ•° ---
                margin_x = 40
                margin_y = 50
                col_gap = 15
                col_count = idx_col_count

                col_width = (page_width - 2 * margin_x - (col_count - 1) * col_gap) / col_count

                line_height = idx_font_size * 1.5
                header_height = idx_font_size * 2.0
                title_font_size = idx_font_size + 8
                lib_title_font_size = idx_font_size + 2

                var_font_size = max(6, idx_font_size - 2)

                # ä¸»å•è¯æˆªæ–­é•¿åº¦
                avg_char_width = idx_font_size * 0.55
                truncation_limit = int(col_width / avg_char_width) - 2
                if truncation_limit < 5: truncation_limit = 5

                # å˜ä½“å•è¯æ¢è¡Œé˜ˆå€¼
                var_avg_char_width = var_font_size * 0.55
                var_truncation_limit = int(col_width / var_avg_char_width) - 4

                current_col = 0
                current_y = margin_y

                idx_page.insert_text((margin_x, 30), "Index of Words", fontsize=title_font_size, color=(0, 0, 0))

                for lib_name, words_dict in final_index_data.items():
                    if not words_dict:
                        continue

                    sorted_origins = sorted(list(words_dict.keys()), key=str.lower)
                    lib_color = final_configs[lib_name]['rgb']

                    needed_height = header_height + line_height
                    if current_y + needed_height > page_height - margin_y:
                        current_col += 1
                        current_y = margin_y
                        if current_col >= col_count:
                            idx_page = doc.new_page()
                            current_col = 0

                    current_x = margin_x + current_col * (col_width + col_gap)

                    idx_page.insert_text((current_x, current_y), f"â–  {lib_name}", fontsize=lib_title_font_size,
                                         color=lib_color)
                    current_y += header_height

                    for origin_word in sorted_origins:

                        # æ ¹æ®æ˜¯å¦å‹¾é€‰ show_variants æ¥å†³å®šæ˜¯å¦å‡†å¤‡å˜ä½“æ•°æ®
                        display_variations = []
                        if show_variants:
                            found_variations = words_dict[origin_word]
                            display_variations = [
                                v for v in found_variations
                                if v.lower() != origin_word.lower()
                            ]
                            display_variations = sorted(list(set(display_variations)))

                        # å˜ä½“è‡ªåŠ¨æ¢è¡Œé¢„è®¡ç®—
                        var_lines = []
                        if display_variations:
                            current_var_line = "("
                            for i, var in enumerate(display_variations):
                                separator = ", " if i > 0 else ""
                                if len(current_var_line + separator + var) > var_truncation_limit:
                                    if i > 0: current_var_line += ","
                                    var_lines.append(current_var_line)
                                    current_var_line = "  " + var
                                else:
                                    current_var_line += separator + var
                            current_var_line += ")"
                            var_lines.append(current_var_line)

                        # è®¡ç®—æœ¬æ¡ç›®éœ€è¦çš„æ€»é«˜åº¦
                        item_height = line_height
                        if var_lines:
                            item_height += len(var_lines) * line_height

                        # æ£€æŸ¥ç©ºé—´
                        if current_y + item_height > page_height - margin_y:
                            current_col += 1
                            current_y = margin_y
                            if current_col >= col_count:
                                idx_page = doc.new_page()
                                current_col = 0
                            current_x = margin_x + current_col * (col_width + col_gap)

                        # 1. ç»˜åˆ¶åŸè¯
                        display_word = origin_word if len(origin_word) < truncation_limit else origin_word[
                                                                                               :truncation_limit] + "..."
                        idx_page.insert_text((current_x, current_y), f"  {display_word}", fontsize=idx_font_size,
                                             color=(0.2, 0.2, 0.2))
                        current_y += line_height

                        # 2. ç»˜åˆ¶å˜ä½“ï¼ˆå¤šè¡Œï¼‰
                        for v_line in var_lines:
                            idx_page.insert_text((current_x + 10, current_y), v_line, fontsize=var_font_size,
                                                 color=(0.5, 0.5, 0.5))
                            current_y += line_height

                    current_y += line_height / 2

        # ä¿å­˜ä¸ç»“æŸ
        status_text.text("ğŸ’¾ æ­£åœ¨æ¸²æŸ“æœ€ç»ˆæ–‡ä»¶...")
        output_path = tmp_input_path.replace(".pdf", "_highlighted_index.pdf")
        doc.save(output_path, garbage=4, deflate=True)
        doc.close()

        progress_bar.progress(100)
        status_text.text("âœ… å®Œæˆï¼")

        cols = st.columns(len(total_stats))
        for idx, (name, count) in enumerate(total_stats.items()):
            cols[idx].metric(label=name, value=count)

        # --- ã€ä¿®æ”¹ç‚¹ã€‘ ä¿®æ­£åçš„é¢„è§ˆé€»è¾‘ ---

        # è¯»å–æ–‡ä»¶å†…å®¹
        with open(output_path, "rb") as file:
            pdf_data = file.read()

        col_dl, col_preview = st.columns([1, 4])

        with col_dl:
            st.download_button(
                "ğŸ“¥ ä¸‹è½½ç»“æœ PDF",
                data=pdf_data,
                file_name=f"Highlight_{uploaded_pdf.name}",
                mime="application/pdf",
                type="primary"
            )

        # ä½¿ç”¨å¤é€‰æ¡†æ§åˆ¶å†…åµŒé¢„è§ˆ
        if st.checkbox("ğŸ‘€ åœ¨çº¿é¢„è§ˆç»“æœ PDF (å±•å¼€/æ”¶èµ·)", value=False):
            base64_pdf = base64.b64encode(pdf_data).decode('utf-8')
            # è¿™é‡Œçš„ height="900px" è¶³å¤Ÿå¤§ï¼Œçœ‹èµ·æ¥åƒä¸€ä¸ªå®Œæ•´é¡µé¢
            pdf_display = f'<iframe src="data:application/pdf;base64,{base64_pdf}" width="100%" height="900px" type="application/pdf" style="border: 1px solid #ddd; border-radius: 5px;"></iframe>'
            st.markdown(pdf_display, unsafe_allow_html=True)

        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        os.unlink(tmp_input_path)
        os.unlink(output_path)
        gc.collect()

    except Exception as e:
        st.error(f"å‡ºé”™: {e}")

elif process_btn:
    st.error("è¯·æ£€æŸ¥é…ç½®ã€‚")